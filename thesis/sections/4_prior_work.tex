%!tex root = ../main.tex

\section{Prior work} \label{sec:prior_work}
%In this section, we discuss the related studies that have been released prior to this work.
%\todo{\(\leftarrow\) is this sentence needed?}
In computer science, we are often interested in finding the best possible (optimal) algorithm for some computational problem.
First, in Section \ref{sec:prior_work:title_a}, we generally discuss the \emph{automation of finding} information about the possible optimal algorithm, and briefly discuss what has been previously done related to the subject, in the field of computer science.
In Section \ref{sec:prior_work:title_b} we narrow our focus on the subject to the field of distributed computing.
In addition, we will discuss relevant automated tools that have been developed prior this work and the complexity classes that are relevant in the LOCAL model.

\subsection{Automation of proving} \label{sec:prior_work:title_a} %Algorithm synthetization
%\todo{Maybe start talking more generally, without mentioning anything about LOCAL or LCL, and explain that in computer science, we are looking for }
Given that we have an interesting computational problem, our ultimate end goal is to find the best possible (i.e. optimal) algorithm for the computational problem.
We would like to learn something new about the computability of the problem in terms of computational complexity, in order to narrow the search for the best algorithm.
There are usually two desirable results we would want to discover.
\begin{itemize}
    \item
    The first desirable result is an efficient algorithm that solves the computational problem.
    The existence of such algorithm would show that the problem is solvable with \emph{at least} at the efficiency of the algorithm.
    \item
    The second desirable result would be the information that such efficient algorithm does not exist at all.
    If there are provably no algorithms with such efficiency, then possible algorithms have to be \emph{less} efficient.
\end{itemize}
We say that the former results, showing existence, an upper bound, or possibility, are \emph{positive} results.
Similarly, the latter results, showing nonexistence, a lower bound, or impossibility, are \emph{negative} results.
In our work, the objective is to find negative results, but we would also like to briefly discuss finding positive results as it is the other side of discovering new information about the computability of computational problems.

Traditionally, positive and negative results for computational problems have been found using the pen-and-paper method.
%\todo{These examples, but in nondistributed way?}
For example, Linial showed in 1987 that there is a deterministic \(\mathcal{O}(\log^* n)\) algorithm for \(\mathcal{O}(\Delta^2)\)-coloring \cite{DBLP:conf/focs/Linial87}.
In a more recent paper from 2010, Barenboim and Elkin showed that there is a deterministic \emph{polylogarithmic} time algorithm for \(\Delta^{1 + o(1)}\)-coloring \cite{DBLP:conf/podc/BarenboimE10}, which is substantially better in terms of the quantity of colors, in comparison to the former paper \cite{DBLP:conf/focs/Linial87} from Linial.

A more recent approach to finding positive or negative results is the \emph{automation} of the whole process.
%The automation of finding these results is a more recent approach in the field.
One could automate the finding of positive or negative results by utilizing massive computational power of modern computers.
The case of negative results is exactly one of our work's objectives and we will discuss the automation of finding these results in the distributed computing in Section \ref{sec:prior_work:title_b}.
But first, what about the automation of finding positive results?

The automation of finding positive results involves creating a tool that takes a specification of desired behavior as an input, and outputs an algorithm that matches the specification, and this method is called \emph{algorithm synthesis} \cite{DBLP:phd/basesearch/Rybicki16}.
For example, in the work of Dramnesc and Jebelean from 2015, the authors manage to automatically synthesize various sorting algorithms including selection sort, insertion sort, quick sort, merge sort and a novel sorting algorithm they call \emph{unbalanced merge sort} \cite{DBLP:journals/jsc/DramnescJ15}.
As another example, in the work of Gulwani et~al. from 2011, the authors present a tool that can efficiently synthesize highly nontrivial 10--20 line loop-free bit vector programs \cite{DBLP:conf/pldi/GulwaniJTV11}.

Propositional satisfiability solvers (SAT solvers) have been used in various synthesis problems to find positive results.
SAT solvers are also used in our implementation to find negative results and we will talk more about them in Section \ref{}\footnote{\todo{Add reference to section where we explain SAT}}, but nevertheless we will next list some examples of previous research.
%We will discuss more about propositional satisfiability solvers in Section \ref{}\footnote{\todo{Add reference to section where we explain SAT}} as they are also used in our implementation for finding negative results, but nevertheless we will next list some examples of previous research.
SAT solvers have been used especially in synthesis of circuits, where one goal is to find optimal Boolean circuits in terms of size.
For example, in the paper from Järvisalo et al.\ \cite{DBLP:conf/sat/JarvisaloKKK12}, the authors present a method to encode an ensemble computation problem as a propositional formula.
The encoding is then fed to a SAT solver to gain either a working circuit design for the ensemble computation problem or a proof of nonexistence.
\todo{Add another example.}






%\todo{algorithm synthesis is by no means easy, it is often undecidable or bla bla bla, check the väikkäri}
%"given a specification of the desired behavior, let the computer find an algorithm that matches the specification"\cite{DBLP:phd/basesearch/Rybicki16}


%In this work we focus on the automation of new discoveries in the distributed computing.
%In addition, there has been considerable work 

%Proofs 
%The first one, that we are targeting at in this thesis, is that we show the problem to not be solvable 
%When we are attempting to 
%
%There has been a lot of effort in showing positive results in the foundations
%
%
%When we look at the 
%From the bird's eye view, our work is one 
\subsection{Automation of proving in distributed computing} \label{sec:prior_work:title_b}


The tools that automate the proving of positive or negative results in distributed computing are called \emph{classifiers}.
A \emph{classifier} can automatically determine a lower bound or an upper bound for an LCL problem.
Currently, we are aware of only small number of different classifiers, and we will list them below in Table \ref{tbl:classifiers}.
%\subsection{Classifiers} \label{sec:prior_work:title_c}



%\subsection{Relevant complexity classes and gaps (or Complexity landscape of LCL's?)}
Generally, there are infinitely many complexity classes, but in the LOCAL model, infinitely many of them turns out to be redundant.
There are 4 main complexity classes in the LOCAL model \url{https://jukkasuomela.fi/landscape-of-locality}
\todo{table of classifiers used in the aleksandr's work and the following recent work:}
\url{https://arxiv.org/abs/2202.08544}
\url{https://github.com/jendas1/poly-classifier}

\begin{table}[h]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{l l l l l l}
    \toprule
    &&&& \multicolumn{2}{c}{Trees} \\
    \cmidrule{5-6}
    Classifier & Labels & Paths & Cycles &Rooted & Unrooted \\\midrule
    Round Eliminator \cite{DBLP:conf/podc/Olivetti20, OlivettiRoundEliminatorGithub, DBLP:conf/podc/Brandt19}
    & {\color{red}Any?} & Yes & No &  No & Yes \\
    %
    Automata-theoretic lens classifier \cite{CyclePathClassifier2020, DBLP:conf/sirocco/ChangSS21}
    & Any & Yes & Yes & Partially\footnote{The implementation does not handle rooted trees, but the theory in the paper applies to some LCL problems in rooted trees.} & No \\
    %
    Tree-classifications (dataset) \cite{TreeClassifications2020}
    & 2, 3 & ? & ? & No  & Yes \\
    %
    TLP Classifier \cite{RocherTlpClassifier2020, Rocher2020}
    & 3 & ? & ? & No  & Yes \\
    %
    Rooted tree classifier \cite{RootedTreeClassifier2021, DBLP:conf/podc/Balliu0OSST21}
    & ? & ? & ? & Yes & No \\
    %
    poly-classifier \cite{PolyClassifier2022, DBLP:journals/corr/abs-2202-08544}
    &?&?&?&?&? \\ \bottomrule
\end{tabular}%
}
\caption{A list of all classifiers we are aware of prior this work.
For each classifier, we list the graph families they target and the amount of labels they support.
By support, we do not necessarily mean efficient.
\todo{Fill all missing cells.}
} \label{tbl:classifiers}
\end{table}

\todo{round eliminator, other classifiers (from aleksandr's lcl-classifier?)}
In our work, we focus only on showing negative results, i.e. we show that something is not possible to achieve, in a form of a lower bound.
In particular, we do

These classifiers generally output complexity classes of the following:
\[1, log^*(n), log(n), n, ...\]
\todo{}
We use the common notations \(\mathcal{O}, o, \Omega, \omega, \Theta \) to define lower and upper bounds.
%\subsection{Relevant complexity classes and gaps (or Complexity landscape of LCL's?)}
Generally, there are infinitely many complexity classes, but in the LOCAL model, infinitely many of them turns out to be redundant.
There are 4 main complexity classes in the LOCAL model \url{https://jukkasuomela.fi/landscape-of-locality}.

The gaps between these complexity classes are ... \todo{Say something about the gaps and cite some paper?}
%TODO somewhere talk about the complexity classes, how there are infinitely many complexity classes, but in some models, range of complexity classes are equal. There are gaps in the complexity thingy.
