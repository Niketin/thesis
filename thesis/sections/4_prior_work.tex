%!tex root = ../main.tex

\section{Prior work} \label{sec:prior_work}
%In this section, we discuss the related studies that have been released prior to this work.
%\todo{\(\leftarrow\) is this sentence needed?}
In computer science, we are often interested in finding the best possible algorithm for some computational problem.
First, in Section~\ref{sec:prior_work:automation_of_proving}, we generally discuss the \emph{automation of finding} information about the best possible algorithm, and we briefly discuss what has been previously done related to the subject, in the field of computer science.
In Section~\ref{sec:prior_work:automation_of_proving_in_dist_comp} we narrow our focus on the subject to the field of distributed computing.
In addition, we will discuss relevant automated tools that have been developed prior this work and the complexity classes that are relevant in the LOCAL model.

\subsection{Automation of proving} \label{sec:prior_work:automation_of_proving} %Algorithm synthetization
%\todo{Maybe start talking more generally, without mentioning anything about LOCAL or LCL, and explain that in computer science, we are looking for }
Given that we have an interesting computational problem, our ultimate end goal is to find the best possible (i.e. optimal) algorithm for the computational problem.
We would like to learn something new about the computability of the problem in terms of computational complexity, in order to narrow the search for the best algorithm.
There are usually two desirable results we would want to discover.
\begin{itemize}
    \item
    The first desirable result is an efficient algorithm that solves the computational problem.
    The existence of such algorithm would show that the problem is solvable with \emph{at least} at the efficiency of the algorithm.
    \item
    The second desirable result would be the information that such efficient algorithm does not exist at all.
    If there are provably no algorithms with such efficiency, then possible algorithms have to be \emph{less} efficient.
\end{itemize}
We say that the former results, showing existence, an upper bound, or possibility, are \emph{positive} results.
Similarly, the latter results, showing nonexistence, a lower bound, or impossibility, are \emph{negative} results.
In our work, the objective is to find negative results, but we would also like to briefly discuss finding positive results as it is the other side of discovering new information about the computability of computational problems.

Traditionally, positive and negative results for computational problems have been found using the pen-and-paper method.
For example, Linial\ \cite{DBLP:conf/focs/Linial87} showed in 1987 that there is a deterministic \(\mathcal{O}(\log^* n)\) algorithm for \(\mathcal{O}(\Delta^2)\)-coloring.
In a more recent paper from 2010, Barenboim and Elkin\ \cite{DBLP:conf/podc/BarenboimE10} showed that there is a deterministic \emph{polylogarithmic} time algorithm for \(\Delta^{1 + o(1)}\)-coloring, which is substantially better in terms of the quantity of colors, in comparison to the former paper \cite{DBLP:conf/focs/Linial87} from Linial.

A more recent approach to finding positive or negative results is the \emph{automation} of the whole process.
One could automate the finding of positive or negative results by utilizing massive computational power of modern computers.
The case of negative results is exactly one of our work's objectives, and we will discuss the automation of finding these results in the distributed computing in Section \ref{sec:prior_work:automation_of_proving_in_dist_comp}.
But first, what about the automation of finding positive results?

The automation of finding positive results involves creating a tool that takes a specification of desired behavior as an input, and outputs an algorithm that matches the specification, and this method is called \emph{algorithm synthesis} \cite{DBLP:phd/basesearch/Rybicki16}.
For example, in the work of Dramnesc and Jebelean from 2015, the authors manage to automatically synthesize various sorting algorithms including selection sort, insertion sort, quick sort, merge sort and a novel sorting algorithm they call \emph{unbalanced merge sort} \cite{DBLP:journals/jsc/DramnescJ15}.
As another example, in the work of Gulwani et~al. from 2011, the authors present a tool that can efficiently synthesize highly nontrivial 10--20 line loop-free bit vector programs \cite{DBLP:conf/pldi/GulwaniJTV11}.

Propositional satisfiability solvers (SAT solvers) have been used in various synthesis problems to find positive results.
SAT solvers are also used in our implementation to find negative results, and we will talk more about them in Section \ref{} (\todo{Add reference to section where we explain SAT}), but nevertheless we will next show an examples of a previous research.
SAT solvers have been used especially in synthesis of circuits, where one goal is to find optimal Boolean circuits in terms of size.
As the example, in the paper from Järvisalo et al.\ \cite{DBLP:conf/sat/JarvisaloKKK12}, the authors present a method to encode an ensemble computation problem as a propositional formula.
The encoding is then fed to a SAT solver to gain either a working circuit design for the ensemble computation problem or a proof of nonexistence.

%\todo{algorithm synthesis is by no means easy, it is often undecidable or bla bla bla, check the väikkäri}
%"given a specification of the desired behavior, let the computer find an algorithm that matches the specification"\cite{DBLP:phd/basesearch/Rybicki16}

\subsection{Automation of proving in distributed computing (or in the LOCAL model?)} \label{sec:prior_work:automation_of_proving_in_dist_comp}


The tools that automate the finding of positive or negative results in distributed computing are called \emph{classifiers}.
A \emph{classifier} can automatically determine a lower bound or an upper bound for an LCL problem.
Currently, we are aware of only small number of different classifiers, and we will list them below in Table \ref{tbl:classifiers}.
These classifiers work in the LOCAL model meaning that the results outputted by the classifiers apply to the model. \todo{This sound weird}

Generally, there are infinitely many complexity classes because there are infinitely many functions.
In the LOCAL model, infinitely many of them turns out to be redundant.
\emph{Gap theorems} show that there are ranges of complexities where there exists no optimal algorithms for LCL problems.
For example, Balliu et al.\ \cite{DBLP:conf/podc/BalliuHOS19} showed that the deterministic complexity of an optimal algorithm is either at most \(\mathcal{O}(1)\) or requires at least \(\Omega(\log^* n)\) rounds.
As another example, \todo{}ASD et al. \ \cite{} showed that there is a gap between \(\Omega(\log n)\) and \(\mathcal{O}(\log^* n)\).
Currently, the main complexities we care about, in the deterministic LOCAL model, are:
\[\mathcal{O}(1), \Theta(\log^* n), \Theta(\log n), \Theta(n).\]
This is the reason why the output complexity for an LCL problem, from a classifier, is typically one of these 4 complexities.

This results in 4 main complexity classes in the deterministic LOCAL model \cite{}.
Due this fact, classifiers in the LOCAL model generally output these complexities for LCL problems.


%\subsection{Relevant complexity classes and gaps (or Complexity landscape of LCL's?)}
 \url{https://jukkasuomela.fi/landscape-of-locality}
\todo{Table of classifiers used in the Aleksandr's work and the following recent work:}
\url{https://arxiv.org/abs/2202.08544}
\url{https://github.com/jendas1/poly-classifier}


\todo{Go through these works, check each fact. Leave some parts empty if necessary (if no information about some part is not available.)}
\begin{table}[h]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{l l l l l l}
    \toprule
    &&&& \multicolumn{2}{c}{Trees} \\
    \cmidrule{5-6}
    Classifier & Labels & Paths & Cycles &Rooted & Unrooted \\\midrule
    Round Eliminator \cite{DBLP:conf/podc/Olivetti20, OlivettiRoundEliminatorGithub, DBLP:conf/podc/Brandt19}
    & {\color{red}Any?} & Yes & No &  No & Yes \\
    %
    Automata-theoretic lens classifier \cite{CyclePathClassifier2020, DBLP:conf/sirocco/ChangSS21}
    & Any & Yes & Yes & Partially\footnote{The implementation does not handle rooted trees, but the theory in the paper applies to some LCL problems in rooted trees.} & No \\
    %
    Tree-classifications (dataset) \cite{TreeClassifications2020}
    & 2, 3 & ? & ? & No  & Yes \\
    %
    TLP Classifier \cite{RocherTlpClassifier2020, Rocher2020}
    & 3 & ? & ? & No  & Yes \\
    %
    Rooted tree classifier \cite{RootedTreeClassifier2021, DBLP:conf/podc/Balliu0OSST21}
    & ? & ? & ? & Yes & No \\
    %
    poly-classifier \cite{PolyClassifier2022, DBLP:journals/corr/abs-2202-08544}
    &?&?&?&?&? \\ \bottomrule
\end{tabular}%
}
\caption{A list of all classifiers we are aware of prior this work.
For each classifier, we list the graph families they target and the amount of labels they support.
By support, we do not necessarily mean efficient.
\todo{Fill all missing cells.}
} \label{tbl:classifiers}
\end{table}

\todo{Round eliminator, other classifiers (from Aleksandr's lcl-classifier?)}
In our work, we focus only on showing negative results, i.e. we show that something is not possible to achieve, in a form of a lower bound.
In particular, we do

These classifiers generally output complexity classes of the following:
\[1, log^*(n), log(n), n, ...\]
\todo{}
We use the common notations \(\mathcal{O}, o, \Omega, \omega, \Theta \) to define lower and upper bounds.
%\subsection{Relevant complexity classes and gaps (or Complexity landscape of LCL's?)}
Generally, there are infinitely many complexity classes, but in the LOCAL model, infinitely many of them turns out to be redundant.
There are 4 main complexity classes in the LOCAL model \url{https://jukkasuomela.fi/landscape-of-locality}.

The gaps between these complexity classes are ... \todo{Say something about the gaps and cite some paper?}
%TODO somewhere talk about the complexity classes, how there are infinitely many complexity classes, but in some models, range of complexity classes are equal. There are gaps in the complexity thingy.
