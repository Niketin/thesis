%!tex root = ../main.tex

\section{Prior work} \label{sec:prior_work}
%In this section, we discuss the related studies that have been released prior to this work.
%\todo{\(\leftarrow\) is this sentence needed?}
In computer science, we are often interested in finding the best possible (optimal) algorithm for some computational problem.
First, in Section \ref{sec:prior_work:title_a}, we generally discuss the \emph{automation of finding} information about the possible optimal algorithm, and briefly discuss what has been previously done related to the subject, in the field of computer science.
In Section \ref{sec:prior_work:title_b} we narrow our focus on the subject to the field of distributed computing.
In addition, we will discuss relevant automated tools that have been developed prior this work and the complexity classes that are relevant in the LOCAL model.

\subsection{Automation of proving} \label{sec:prior_work:title_a} %Algorithm synthetization
%\todo{Maybe start talking more generally, without mentioning anything about LOCAL or LCL, and explain that in computer science, we are looking for }
In computer science, given that we have an interesting computational problem, our ultimate end goal is to find the best possible (i.e. optimal) algorithm for the computational problem.
We would like to learn something new about the computability of the problem in terms of computational complexity, in order to narrow the search for the best algorithm.
There are usually two desirable results we would want to discover.
\begin{itemize}
    \item
    The first desirable result is an efficient algorithm that solves the computational problem.
    The existence of such algorithm would show that the problem is solvable with \emph{at least} at the efficiency of the algorithm.
    \item
    The second desirable result would be the information that such efficient algorithm does not exist at all.
    If there are provably no algorithms with such efficiency, then possible algorithms have to be \emph{less} efficient.
\end{itemize}
We say that the former results, showing existence, an upper bound, or possibility, are \emph{positive} results.
Similarly, the latter results, showing nonexistence, a lower bound, or impossibility, are \emph{negative} results.
In our work, the objective is to find negative results, but we would also like to briefly discuss finding positive results as it is the other side of discovering new information about the computability of computational problems.

Traditionally, positive and negative results for computational problems have been found using the pen-and-paper method.
%\todo{These examples, but in nondistributed way?}
For example, Linial showed in 1987 that there is a deterministic \(\mathcal{O}(\log^* n)\) algorithm for \(\mathcal{O}(\Delta^2)\)-coloring \cite{DBLP:conf/focs/Linial87}.
In a more recent paper from 2010, Barenboim and Elkin showed that there is a deterministic \emph{polylogarithmic} time algorithm for \(\Delta^{1 + o(1)}\)-coloring \cite{DBLP:conf/podc/BarenboimE10}, which is substantially better in terms of the quantity of colors, in comparison to the former paper \cite{DBLP:conf/focs/Linial87} from Linial.

A more recent approach to finding positive or negative results is the \emph{automation} of the whole process
%The automation of finding these results is a more recent approach in the field.
One could automate the finding of positive or negative results by utilizing massive computational power of modern computers.
The case of negative results is exactly one of our work's objectives and we will discuss the automation of finding these results in the distributed computing in Section \ref{sec:prior_work:title_b}.
But first, what about the automation of finding positive results?

The automation of finding positive results involves creating a tool that takes a specification of desired behavior as an input, and outputs an algorithm that matches the specification, and this method is called \emph{algorithm synthesis} \cite{DBLP:phd/basesearch/Rybicki16}.
For example, in the work of Dramnesc and Jebelean from 2015, the authors manage to automatically synthesize various sorting algorithms including selection sort, insertion sort, quick sort, merge sort and a novel sorting algorithm they call \emph{unbalanced merge sort} \cite{DBLP:journals/jsc/DramnescJ15}.
As another example, in the work of Gulwani et~al. from 2011, the authors present a tool that can efficiently synthesize highly nontrivial 10-20 line loop-free bit vector programs \cite{DBLP:conf/pldi/GulwaniJTV11}.

Satisfiability solvers have been used in various synthesis problems to find positive results.
We will discuss more about satisfiability solvers in Section \ref{}\footnote{\todo{Add reference to section where we explain SAT}} as they are also used in our implementation for finding negative results, but nevertheless we will next list some examples of previous research.




%\todo{algorithm synthesis is by no means easy, it is often undecidable or bla bla bla, check the väikkäri}
%"given a specification of the desired behavior, let the computer find an algorithm that matches the specification"\cite{DBLP:phd/basesearch/Rybicki16}


%In this work we focus on the automation of new discoveries in the distributed computing.
%In addition, there has been considerable work 

%Proofs 
%The first one, that we are targeting at in this thesis, is that we show the problem to not be solvable 
%When we are attempting to 
%
%There has been a lot of effort in showing positive results in the foundations
%
%
%When we look at the 
%From the bird's eye view, our work is one 
\subsection{Automation of proving in distributed computing} \label{sec:prior_work:title_b}
\todo{start writing this chapter. Remove the examples below as they are used in the above section. combine this section with classifiers, as they are implementations of automated provers.}
Traditionally, positive and negative results for distributed computational problems have been found using the pen-and-paper method.
For example, Linial showed in 1987 that there is a deterministic \(\mathcal{O}(\log^* n)\) algorithm for \(\mathcal{O}(\Delta^2)\)-coloring \cite{DBLP:conf/focs/Linial87}.
In a more recent paper from 2010, Barenboim and Elkin showed that there is a deterministic \emph{polylogarithmic} time algorithm for \(\Delta^{1 + o(1)}\)-coloring \cite{DBLP:conf/podc/BarenboimE10}, which is substantially better in terms of the quantity of colors, in comparison to the former paper \cite{DBLP:conf/focs/Linial87} from Linial.
\subsection{Classifiers} \label{sec:prior_work:title_c}


A \emph{classifier} is a tool that can automatically determine a lower bound or an upper bound for an LCL problem.


%\subsection{Relevant complexity classes and gaps (or Complexity landscape of LCL's?)}
Generally, there are infinitely many complexity classes, but in the LOCAL model, infinitely many of them turns out to be redundant.
There are 4 main complexity classes in the LOCAL model \url{https://jukkasuomela.fi/landscape-of-locality}
\todo{table of classifiers used in the aleksandr's work and the following recent work:}
\url{https://arxiv.org/abs/2202.08544}
\url{https://github.com/jendas1/poly-classifier}
\todo{round eliminator, other classifiers (from aleksandr's lcl-classifier?)}
In our work, we focus only on showing negative results, i.e. we show that something is not possible to achieve, in a form of a lower bound.
In particular, we do

These classifiers generally output complexity classes of the following:
\[1, log^*(n), log(n), n, ...\]
\todo{}
We use the common notations \(\mathcal(O), o, \Omega, \omega, \Theta \) to define lower and upper bounds.
%\subsection{Relevant complexity classes and gaps (or Complexity landscape of LCL's?)}
Generally, there are infinitely many complexity classes, but in the LOCAL model, infinitely many of them turns out to be redundant.
There are 4 main complexity classes in the LOCAL model \url{https://jukkasuomela.fi/landscape-of-locality}.

The gaps between these complexity classes are ... \todo{Say something about the gaps and cite some paper?}

%\subsection{Lower and upper bounds of LCL's} \label{sec:prior_work:title_c}

% %TODO I'll draft some sections here that I probably should consider writing about.
% % Some might be really similar or even identical.
% \subsection{\color{red}These sections are WIP, they do not necessarily stay this way, and each section probably does not stay under their own section}
% \subsection{Lower and upper bounds of LCL's}
% \subsection{Complexity classifications of LCL's}
% \subsection{Computation of lower and upper bounds}
% %TODO somewhere talk about the complexity classes, how there are infinitely many complexity classes, but in some models, range of complexity classes are equal. There are gaps in the complexity thingy.
% \subsection{Computation in complexity theory}
% \subsection{Complexity landscape of LCL's}
% \subsection{Computer assisted something in complexity theory}


%tietojenk'sittelytieteess' hjalutaan l;yt'' paras mahdollinen algoritmi jollekin laskennaliselle ongelmalle